package hdm.developmentlab.ebi.eve_implementation.events;

import eventprocessing.utils.model.EventUtils;

public enum TimeReferenceEnum {

//    //Feste Zeitbereiche
//	Chunker chunks = new Chunker();
//
//	ArrayList<String> test1 =new ArrayList<>();
//	test1.add("{\"Instanz\":{\"type\":\"http://semanticweb.org/jennifertran/ontologies/2018/0/dokumentenRepraesentation#Project\"},\"Keyword\":{\"type\":\"Highnet\"}}");
//	ArrayList<String> test =new ArrayList<>();
//	ArrayList<String> test2 =new ArrayList<>();
//	test2.add("{\\\"Instanz\\\":{\\\"type\\\":\\\"http://semanticweb.org/jennifertran/ontologies/2018/0/dokumentenRepraesentation#CostPlan\\\"},\\\"Keyword\\\":{\\\"type\\\":\\\"Document\\\"}}");
//	test2.add("{\\\"Instanz\\\":{\\\"type\\\":\\\"http://semanticweb.org/jennifertran/ontologies/2018/0/dokumentenRepraesentation#Thomas\\\"},\\\"Keyword\\\":{\\\"type\\\":\\\"Person\\\"}}");
//	chunks.addChunkContent("uri");
//	chunks.addChunkContent("fhad");
//	chunks.addChunkContent("Mond");
//	Chunker chunks1= new Chunker();
//	chunks.addChunkContent("hilfe");
//	chunks.addChunkContent("Hallo");
//	chunks.addSemanticToChunk("Hallo", test1);
//	chunks.addSemanticToChunk("Mond", test1);
//	chunks1.addChunkContent("chunk");
//	chunks1.addSemanticToChunk("chunk", test2);
//
//	ArrayList<String> list = chunks1.readChunks();
//	for (int i = 0; i < list.size(); i++) {
//		ArrayList<String> list1 = (ArrayList<String>) chunks1.readSemanticOfChunk(list.get(i));
//		list1.get(i).contains("project");
//	}
//	chunks1.printList();


}

